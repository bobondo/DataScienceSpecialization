# run each expression 1000 times and store the time taken
time_DT <- system.time(for (i in 1:1000) DT[,mean(pwgtp15),by=SEX])
time_sapply <- system.time(for (i in 1:1000) sapply(split(DT$pwgtp15,DT$SEX),mean))
time_tapply <- system.time(for (i in 1:1000) tapply(DT$pwgtp15,DT$SEX,mean))
time_mean1 <-system.time(for (i in 1:1000) mean(DT[DT$SEX==1,]$pwgtp15))
time_DT <- system.time(for (i in 1:1000) DT[,mean(pwgtp15),by=SEX])
time_sapply <- system.time(for (i in 1:1000) sapply(split(DT$pwgtp15,DT$SEX),mean))
time_tapply <- system.time(for (i in 1:1000) tapply(DT$pwgtp15,DT$SEX,mean))
time_mean1 <-system.time(for (i in 1:1000) mean(DT[DT$SEX==1,]$pwgtp15))
time_mean2 <-system.time(for (i in 1:1000) mean(DT[DT$SEX==2,]$pwgtp15))
time_mean <- time_mean1 + time_mean2
time_DT
time_sapply
time_mean1
time_mean2
install.packages("RMySQL") # delete line after install
install.packages("httr") # delete line after install
install.packages("rhdf5") # delete line after install
install.packages("RMySQL") # delete line after install
install.packages("httr") # delete line after install
install.packages("rhdf5") # delete line after install
library(httr)
url_data <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(url_data, "fss06hid" method="curl")
??download.file
download.file(url_data, fss06hid, method="curl")
download.file(url_data, destfile="fss06hid", method="curl")
download.file(url_data, destfile="fss06hid.csv", method="curl")
download.file(url_data, fss06hid.csv, method="curl")
destfile <- "fss06hid.csv"
download.file(url_data, fss06hid.csv, method="curl")
download.file(url_data, destfile, method="curl")
download.file(url_data, method="curl")
download.file(url_data, destfile="fss06hid.csv", method="curl")
library(httr)
url_data <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(url_data, destfile="fss06hid.csv", method="curl")
data <- read.csv("ss06hid.csv")
data <- read.csv("fss06hid.csv")
download.file(url_data, destfile="fss06hid.csv") #, method="curl")
data <- read.csv("fss06hid.csv")
logicalvector <- data$ACR==3 & data$AGS==6
first3 <- which(logicalvector)[1:3] # which() treats NAs as FALSE
first3
data <- read.csv("fss06hid.csv")
agricultureLogical <- data$ACR==3 & data$AGS==6
first3 <- which(agricultureLogical)[1:3] # which() treats NAs as FALSE
first3
library(jpeg)
install.packages("jpeg")
library(jpeg)
url_q2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(url_q2, destfile="jeff.jpg", method="curl")
download.file(url_q2, destfile="jeff.jpg")
pic <- readJPEG("jeff.jpg", native = TRUE)
quantile(pic)
url_q2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(url_q2, destfile="jeff.jpg")
pic <- readJPEG("jeff.jpg", native = TRUE)
??download.file
download.file(url_q2, destfile="jeff.jpg", mode="wb")
pic <- readJPEG("jeff.jpg", native = TRUE)
quantile(pic)
quantile(pic). probs=c(0.3,0.8)
quantile(pic, probs=c(0.3,0.8))
library(data.table)
install.packages('data.table')
library(data.table)
url_q3a <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(url_q3a, destfile="GDP.csv")
GDP <- data.table(read.csv("GDP.csv", skip = 4, nrows = 191))
GDP <- GDP[X != ""]
GDP <- GDP[, list(X, X.1, X.3, X.4)]
setnames(GDP, c("X", "X.1", "X.3", "X.4"), c("CountryCode", "rankingGDP", "Long.Name", "GDP"))
url_q3b <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(url_q3b, destfile="EDSTATS_Country.csv")
EDSTATS <- data.table(read.csv("EDSTATS_Country.csv"))
data2 <- merge(GDP, EDSTATS, all = TRUE, by = c("CountryCode"))
sum(!is.na(unique(data2$rankingGDP)))
data2[, mean(rankingGDP, na.rm = TRUE), by = Income.Group]
breaks <- quantile(data2$rankingGDP, probs = seq(0, 1, 0.2), na.rm = TRUE)
data2$quantileGDP <- cut(data2$rankingGDP, breaks = breaks)
data2[Income.Group == "Lower middle income", .N, by = c("Income.Group", "quantileGDP")]
rank_quantile<-cut(md$Ranking,
breaks = quantile (md$Ranking, c (seq(0, 1, 0.2))),
include.lowest = TRUE)
# class(rank_quantile) = factor
aggregate (md$Income.Group, list(rank_quantile), FUN = table)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "gdp.csv", method = "curl")
gdp <- read.csv("./gdp.csv")
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl1, destfile = "edu.csv", method = "curl")
edu <- read.csv("./edu.csv")
X=CountryCode
names(gdp)
names(edu)
head(gdp)
head(edu)
gdpclean<-gdp[5:194,]
mergedData=as.data.frame(merge(gdpclean,edu,by.x="X",by.y="CountryCode"))
mergedData$Gross.domestic.product.2012 = as.numeric(as.character(mergedData$Gross.domestic.product.2012))
summary(mergedData[mergedData$Income.Group=="High income: OECD",])
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "gdp.csv", method = "curl")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "gdp.csv")
gdp <- read.csv("./gdp.csv")
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl1, destfile = "edu.csv", method = "curl")
edu <- read.csv("./edu.csv")
X=CountryCode
names(gdp)
names(edu)
head(gdp)
head(edu)
gdpclean<-gdp[5:194,]
mergedData=as.data.frame(merge(gdpclean,edu,by.x="X",by.y="CountryCode"))
mergedData$Gross.domestic.product.2012 = as.numeric(as.character(mergedData$Gross.domestic.product.2012))
summary(mergedData[mergedData$Income.Group=="High income: OECD",])
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "gdp.csv")
gdp <- read.csv("./gdp.csv")
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl1, destfile = "edu.csv")
edu <- read.csv("./edu.csv")
X=CountryCode
names(gdp)
names(edu)
head(gdp)
head(edu)
gdpclean<-gdp[5:194,]
mergedData=as.data.frame(merge(gdpclean,edu,by.x="X",by.y="CountryCode"))
mergedData$Gross.domestic.product.2012 = as.numeric(as.character(mergedData$Gross.domestic.product.2012))
summary(mergedData[mergedData$Income.Group=="High income: OECD",])
quantile(mergedData$Gross.domestic.product.2012,probs=c(0.2,0.4,0.6,0.8,1))
library(Hmisc)
mergedData$gdp=cut2(mergedData$Gross.domestic.product.2012,g=5)
table(mergedData$Income.Group,mergedData$gdp)
install.packages("hmisc")
install.packages("Hmisc")
library(Hmisc)
mergedData$gdp=cut2(mergedData$Gross.domestic.product.2012,g=5)
table(mergedData$Income.Group,mergedData$gdp)
setwd("C:/Users/jabondo/desktop/Dropbox/Coursera_DSS/3_GetData/quiz1")
setwd("C:\Users\jabondo\Desktop\Dropbox\Coursera_DSS\3_GetData\quiz1")
setwd("C:/Users/jabondo/desktop/Dropbox/Coursera_DSS/3_GetData/quiz1")
if (!file.exists("3_GetData")) {
dir.create("3_GetData")
}
## DOWNLOAD FILE
## DOWNLOAD FILE
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl1, destfile = "3_quiz1.csv")
dateDownloaded <- date()
## READ FILE
idahodata <- read.csv("3_quiz1.csv", sep = ",", header = TRUE)
head(idahodata)
names(idahodata)
## check the value of properties and table out to see <$1m
value <- idahodata$VAL
table(value)
countval <- value[c(24:24)]
countval
head(value)
countval <- as.numerical(value[c(24:24)])
countval <- as.character(value[c(24:24)])
countval
length(idaho_housing$VAL[!is.na(idaho_housing$VAL) & idaho_housing$VAL==24])
length(idahodata$VAL[!is.na(idahodata$VAL) & idahodata$VAL==24])
countmill <- length(idahodata$VAL[!is.na(idahodata$VAL) & idahodata$VAL==24])
countmill
fileUrl3 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileUrl3, destfile = "3_quiz1.xslx", mode="wb")
dateDownloaded <- date()
## read xlsx file
options(java.parameters = "-Xmx1000m")
library(xlsx)
install.package("xlsx")
install.packages("xlsx")
#install.packages("xlsx")
library(xlsx)
dataAll <- read.xlsx("3_quiz1.xslx",  sheetIndex=1, header=TRUE)
head(dataAll)
colIndex <- 7:15
rowIndex <- 18:23
file4 <- "3_quiz1.xslx"
dat <- read.xlsx("3_quiz1.xslx", sheetIndex=1, colIndex=colIndex, rowIndex=rowIndex)
dat
sum(dat$Zip*dat$Ext,na.rm=T)
fileUrl4 <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(fileUrl4, destfile = "3_quiz1.xml")
library(XML)
install.packages("XML")
library(XML)
# parse the XML from the URL
doc <- xmlTreeParse(fileUrl4, useInternal=TRUE)
rootNode <- xmlRoot(doc)
head(rootNode)
# find all zipcode tags
prezipcode <- xpathSApply(rootNode, "//zipcode", xmlValue)
prezipcode
length(prezipcode)
head(prezipcode)
# filter for specific zip code
zipspecific <- prezipcode[prezipcode==21231]
zipspecific
# return the number of zipcodes
length(zipspecific)
install.packages("data.table")
library(data.table)
# check if a data folder exists; if not then create one
fileUrl5 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl5, destfile = "UScommunities.csv", mode="wb" )
dateDownloaded <- date()
list.files()
# read the csv file
DT <- fread("UScommunities.csv")
# the following functions produce an error, and not desired output
time_DT <- system.time(for (i in 1:1000) DT[,mean(pwgtp15),by=SEX])
time_sapply <- system.time(for (i in 1:1000) sapply(split(DT$pwgtp15,DT$SEX),mean))
time_tapply <- system.time(for (i in 1:1000) tapply(DT$pwgtp15,DT$SEX,mean))
time_mean1 <-system.time(for (i in 1:1000) mean(DT[DT$SEX==1,]$pwgtp15))
time_mean2 <-system.time(for (i in 1:1000) mean(DT[DT$SEX==2,]$pwgtp15))
time_mean <- time_mean1 + time_mean2
time_DT
time_sapply
time_mean1
time_mean2
# sapply is shortest
install.packages("RMySQL") # comment line out after install
install.packages("httr") # comment line out after install
install.packages("rhdf5") # comment line out after install
install.packages("sqldf") # comment line out after install
library(httr)
oauth_endpoints("github")
dss_3_getdata <- oauth_app("github", "449817f2e05981226e13", "36fb9b72f9f1485d52bf166c33211c656d9d8339")
# get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), dss_3_getdata)
github_token <- oauth2.0_token(oauth_endpoints("github"), dss_3_getdata)
# set up configuration with token for configuration
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
gtoken <- config(token = github_token)
oauth_endpoints("github")
dss_3_getdata <- oauth_app("github", "449817f2e05981226e13", "36fb9b72f9f1485d52bf166c33211c656d9d8339")
# get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), dss_3_getdata)
# set up configuration with token for configuration
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
dss_3_getdata <- oauth_app("github", "449817f2e05981226e13", "36fb9b72f9f1485d52bf166c33211c656d9d8339")
# get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), dss_3_getdata)
# set up configuration with token for configuration
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
# load url
BROWSE("https://api.github.com/users/jtleek/repos",authenticate("Access Token","x-oauth-basic","basic"))
library(sqldf)
acs <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", header=T, sep=",")
head(acs)
testsol1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
testsol2 <- sqldf("select pwgtp1 from acs")
testsol3 <- sqldf("select * from acs where AGEP < 50 and pwgtp1")
testsol4 <- sqldf("select * from acs where AGEP < 50")
testsol1
testsol2
testsol3
testsol4
hurl <- "http://biostat.jhsph.edu/~jleek/contact.html"
con <- url(hurl)
htmlCode <- readLines(con)
close(con)
sapply(htmlCode[c(10, 20, 30, 100)], nchar)
data <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", header=T)
head(data)
dim(data)
file_name <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
df <- read.fwf(file=file_name,widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
head(df)
sum(df[, 4])
setwd("C:/Users/jabondo/desktop/Dropbox/Coursera_DSS/3_GetData/quiz1")
setwd("C:/Users/jabondo/desktop/Dropbox/Coursera_DSS/3_GetData/quiz2")
###### QUIZ 2 #####################
###################################
install.packages("RMySQL") # comment line out after install
install.packages("httr") # comment line out after install
install.packages("rhdf5") # comment line out after install
install.packages("sqldf") # comment line out after install
install.packages("httr")
install.packages("sqldf")
library(httr)
# create object for registered application
oauth_endpoints("github")
dss_3_getdata <- oauth_app("github", "449817f2e05981226e13", "36fb9b72f9f1485d52bf166c33211c656d9d8339")
# get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), dss_3_getdata)
library(httr)
# create object for registered application
oauth_endpoints("github")
dss_3_getdata <- oauth_app("github", "449817f2e05981226e13", "36fb9b72f9f1485d52bf166c33211c656d9d8339")
# get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), dss_3_getdata)
# set up configuration with token for configuration
oauth_endpoints("github")
dss_3_getdata <- oauth_app("github", "449817f2e05981226e13", "36fb9b72f9f1485d52bf166c33211c656d9d8339")
setwd("C:/Users/jabondo/desktop/Dropbox/Coursera_DSS/3_GetData/quiz2")
library(httr)
# create object for registered application
setwd("C:/Users/jabondo/desktop/Dropbox/Coursera_DSS/3_GetData/quiz1")
cs
library(httr)
setwd("C:/Users/jabondo/desktop/Dropbox/Coursera_DSS/3_GetData/quiz2")
library(httr)
# create object for registered application
oauth_endpoints("github")
dss_3_getdata <- oauth_app("github", "449817f2e05981226e13", "36fb9b72f9f1485d52bf166c33211c656d9d8339")
# get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), dss_3_getdata)
# set up configuration with token for configuration
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
library(sqldf)
acs <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", header=T, sep=",")
head(acs)
testsol1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
testsol2 <- sqldf("select pwgtp1 from acs")
testsol3 <- sqldf("select * from acs where AGEP < 50 and pwgtp1")
testsol4 <- sqldf("select * from acs where AGEP < 50")
testsol1
testsol2
testsol3
testsol4
## QUESTION 3
## Using the same data frame you created in the previous problem,
## what is the equivalent function to
##
unique(acs$AGEP)
## QUESTION 4
## How many characters are in the 10th, 20th, 30th and 100th lines of HTML from this page:
## http://biostat.jhsph.edu/~jleek/contact.html
## (Hint: the nchar() function in R may be helpful)
hurl <- "http://biostat.jhsph.edu/~jleek/contact.html"
hurl <- "http://biostat.jhsph.edu/~jleek/contact.html"
con <- url(hurl)
htmlCode <- readLines(con)
close(con)
sapply(htmlCode[c(10, 20, 30, 100)], nchar)
data <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", header=T)
head(data)
dim(data)
file_name <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
df <- read.fwf(file=file_name,widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
head(df)
sum(df[, 4])
library(httr)
url_data <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
setwd("C:/Users/jabondo/desktop/Dropbox/Coursera_DSS/3_GetData/quiz3")
library(httr)
url_data <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(url_data, destfile="fss06hid.csv") #, method="curl")
data <- read.csv("fss06hid.csv")
agricultureLogical <- data$ACR==3 & data$AGS==6
first3 <- which(agricultureLogical)[1:3]
first3
install.packages("jpeg")
library(jpeg)
url_q2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(url_q2, destfile="jeff.jpg", mode="wb")
pic <- readJPEG("jeff.jpg", native = TRUE)
quantile(pic, probs=c(0.3,0.8))
library(data.table)
url_q3a <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(url_q3a, destfile="GDP.csv")
GDP <- data.table(read.csv("GDP.csv", skip = 4, nrows = 191))
GDP <- GDP[X != ""]
GDP <- GDP[, list(X, X.1, X.3, X.4)]
setnames(GDP, c("X", "X.1", "X.3", "X.4"), c("CountryCode", "rankingGDP", "Long.Name", "GDP"))
url_q3b <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(url_q3b, destfile="EDSTATS_Country.csv")
EDSTATS <- data.table(read.csv("EDSTATS_Country.csv"))
data2 <- merge(GDP, EDSTATS, all = TRUE, by = c("CountryCode"))
sum(!is.na(unique(data2$rankingGDP)))
data2 <- merge(GDP, EDSTATS, all = TRUE, by ("CountryCode"))
data2 <- merge(GDP, EDSTATS, all = TRUE, by index("CountryCode"))
?indices
??indices
data2 <- merge(GDP, EDSTATS, all = TRUE)
?merge
data2 <- merge(GDP, EDSTATS, all = TRUE, by = "CountryCode")
data2 <- merge(GDP, EDSTATS, all = TRUE, by = CountryCode)
data2 <- merge(GDP, EDSTATS, all = TRUE, by = "CountryCode")
data2 <- merge(GDP, EDSTATS, all = TRUE, by="CountryCode")
data2 <- merge(GDP, EDSTATS, all = TRUE, by=c("CountryCode"))
data2 <- merge(EDSTATS,GDP,  all = TRUE, by=c("CountryCode"))
sum(!is.na(unique(data2$rankingGDP)))
data2[order(rankingGDP, decreasing = TRUE), list(CountryCode, Long.Name.x, Long.Name.y, rankingGDP, GDP)][13]
data2[, mean(rankingGDP, na.rm = TRUE), by = Income.Group]
breaks <- quantile(data2$rankingGDP, probs = seq(0, 1, 0.2), na.rm = TRUE)
data2$quantileGDP <- cut(data2$rankingGDP, breaks = breaks)
data2[Income.Group == "Lower middle income", .N, by = c("Income.Group", "quantileGDP")]
###########################################another way for q3-5
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "gdp.csv")
gdp <- read.csv("./gdp.csv")
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl1, destfile = "edu.csv")
edu <- read.csv("./edu.csv")
X=CountryCode
names(gdp)
names(edu)
head(gdp)
head(edu)
gdpclean<-gdp[5:194,]
mergedData=as.data.frame(merge(gdpclean,edu,by.x="X",by.y="CountryCode"))
mergedData$Gross.domestic.product.2012 = as.numeric(as.character(mergedData$Gross.domestic.product.2012))
summary(mergedData[mergedData$Income.Group=="High income: OECD",])
quantile(mergedData$Gross.domestic.product.2012,probs=c(0.2,0.4,0.6,0.8,1))
install.packages("Hmisc")
library(Hmisc)
mergedData$gdp=cut2(mergedData$Gross.domestic.product.2012,g=5)
table(mergedData$Income.Group,mergedData$gdp)
data2 <- merge(EDSTATS,GDP,  all = TRUE, by.x=c("CountryCode"))
data2 <- merge(EDSTATS,GDP,  all = TRUE, by.y=c("CountryCode"))
setwd("C:/Users/jabondo/desktop/Dropbox/Coursera_DSS/3_GetData/quiz4")
# QUESTION 1
# The American Community Survey distributes downloadable data about United States communities.
# https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv
# Download the 2006 microdata survey about housing for the state of Idaho using download.file() from here:
# and load the data into R. The code book, describing the variable names is here:
# https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf
# Apply strsplit() to split all the names of the data frame on the characters "wgtp".
# What is the value of the 123 element of the resulting list?
library(httr)
surveydata <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(surveydata)
download.file(surveydata, destfile = "Fss06hid.csv")
surveydatadict <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf"
download.file(surveydatadict)
surveydata <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(surveydata, destfile = "ss06hid.csv")
surveydatadict <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf"
download.file(surveydatadict, destfile="PUMSDataDict06.pdf")
data <- read.table("Fss06hid.csv", header = TRUE, sep = ",")
data <- read.table("ss06hid.csv", header = TRUE, sep = ",")
x <- names(data)
y <- strsplit(x, "wgtp")
y[123]
library(data.table)
gdpdata <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(gdpdata)
gdpdata <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(gdpdata, destfile="GDP.csv")
GDP <- data.table(read.csv("GDP.csv", skip = 4, nrows = 191))
GDP <- GDP[X != ""]
GDP <- GDP[, list(X, X.1, X.3, X.4)]
setnames(GDP, c("X", "X.1", "X.3", "X.4"), c("CountryCode", "rankingGDP", "Long.Name", "GDP"))
columnagdp <- as.numeric(gsub(",", "", GDP$GDP))
mean(columnagdp, na.rm = TRUE)
isUnited <- grepl("^United", GDP$Long.Name)
summary(isUnited)
gdpdata2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(gdpdata2)
download.file(gdpdata2, destfile="EDSTATS_Country.csv")
EDSTATS <- data.table(read.csv("EDSTATS_Country.csv"))
data2 <- merge(GDP, EDSTATS, all = TRUE, by = c("CountryCode"))
FiscalYearEnd <- grepl("fiscal year end", tolower(data2$Special.Notes))
data2 <- merge(GDP, EDSTATS, all = TRUE, by = c("CountryCode"))
FiscalYearEnd <- grepl("fiscal year end", tolower(data2$Special.Notes))
isJune <- grepl("june", tolower(data2$Special.Notes))
table(FiscalYearEnd, isJune)
gdpdata2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(gdpdata2, destfile="GDP.csv")
GDP <- data.table(read.csv("GDP.csv"))
gdpdata3 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(gdpdata3, destfile="EDSTATS_Country.csv")
EDSTATS <- data.table(read.csv("EDSTATS_Country.csv"))
data2 <- merge(GDP, EDSTATS, all = TRUE, by = c("CountryCode"))
colnames(GDP)[colnames(GDP)==""] <- "new_name"
preGDP <- data.table(read.csv("GDP.csv"))
GDP <- preGDP[4:nrow(preGDP)]
colnames(GDP)[colnames(GDP)==""] <- "CountryCode"
?setnames
setnames(GDP,c("","US dollars)"),c("CountryCode","Millions of US Dollars"))
setnames(GDP,"","CountryCode")
setnames(GDP," ","CountryCode")
head(GDP)
setnames(GDP,"X Gross.domestic.product.2012","CountryCode")
setnames(GDP,"Gross.domestic.product.2012","CountryCode")
setnames(GDP,"3","Millions of Dollars")
setnames(GDP,"4","Millions of Dollars")
setnames(GDP,"X.4","Millions of Dollars")
gdpdata3 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(gdpdata3, destfile="EDSTATS_Country.csv")
EDSTATS <- data.table(read.csv("EDSTATS_Country.csv"))
data2 <- merge(GDP, EDSTATS, all = TRUE, by = c("CountryCode"))
data2 <- merge(GDP, EDSTATS, all = TRUE, by ="CountryCode")
head(GDP)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
addmargins(table(year(sampleTimes), weekdays(sampleTimes)))
